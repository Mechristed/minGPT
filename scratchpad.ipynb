{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_dl = DataLoader(training_data, batch_size=bs)\n",
    "test_dl = DataLoader(test_data, batch_size=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.dataset[0][0].shape # 28 x 28 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61a88790d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_dl.dataset[0][0].numpy().squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([64]) torch.int64\n",
      "Shape of X [N, C, H, W]: torch.Size([16, 1, 28, 28])\n",
      "Shape of y [N]: torch.Size([16]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dl:\n",
    "  print(f'Shape of X [N, C, H, W]: {X.shape}')\n",
    "  print(f'Shape of y [N]: {y.shape} {y.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(NN, self).__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "      nn.Linear(28*28, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 10),\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits\n",
    "\n",
    "model = NN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  model.train()\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device) # independent vars (img), dependent vars (actuals)\n",
    "\n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # Bcakpropagate\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      loss, current = loss.item(), batch * len(X)\n",
    "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    # Disabling gradient calculation is useful for inference, when you are sure that you will not call Tensor.backward()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\n",
      "loss: 2.307292 [    0/60000]\n",
      "loss: 2.306511 [ 6400/60000]\n",
      "loss: 2.284371 [12800/60000]\n",
      "loss: 2.272700 [19200/60000]\n",
      "loss: 2.264800 [25600/60000]\n",
      "loss: 2.232742 [32000/60000]\n",
      "loss: 2.241955 [38400/60000]\n",
      "loss: 2.214750 [44800/60000]\n",
      "loss: 2.211560 [51200/60000]\n",
      "loss: 2.174057 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 2.176182 \n",
      "\n",
      "Epoch 2/5\n",
      "\n",
      "loss: 2.189626 [    0/60000]\n",
      "loss: 2.189616 [ 6400/60000]\n",
      "loss: 2.129885 [12800/60000]\n",
      "loss: 2.141274 [19200/60000]\n",
      "loss: 2.109900 [25600/60000]\n",
      "loss: 2.044313 [32000/60000]\n",
      "loss: 2.076156 [38400/60000]\n",
      "loss: 2.006998 [44800/60000]\n",
      "loss: 2.008940 [51200/60000]\n",
      "loss: 1.932645 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.936756 \n",
      "\n",
      "Epoch 3/5\n",
      "\n",
      "loss: 1.971336 [    0/60000]\n",
      "loss: 1.948920 [ 6400/60000]\n",
      "loss: 1.831878 [12800/60000]\n",
      "loss: 1.866642 [19200/60000]\n",
      "loss: 1.766349 [25600/60000]\n",
      "loss: 1.709656 [32000/60000]\n",
      "loss: 1.733891 [38400/60000]\n",
      "loss: 1.634309 [44800/60000]\n",
      "loss: 1.645514 [51200/60000]\n",
      "loss: 1.538868 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 1.557761 \n",
      "\n",
      "Epoch 4/5\n",
      "\n",
      "loss: 1.624343 [    0/60000]\n",
      "loss: 1.587322 [ 6400/60000]\n",
      "loss: 1.438033 [12800/60000]\n",
      "loss: 1.507085 [19200/60000]\n",
      "loss: 1.380252 [25600/60000]\n",
      "loss: 1.379613 [32000/60000]\n",
      "loss: 1.394563 [38400/60000]\n",
      "loss: 1.316428 [44800/60000]\n",
      "loss: 1.339646 [51200/60000]\n",
      "loss: 1.242691 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.268057 \n",
      "\n",
      "Epoch 5/5\n",
      "\n",
      "loss: 1.351135 [    0/60000]\n",
      "loss: 1.325272 [ 6400/60000]\n",
      "loss: 1.164249 [12800/60000]\n",
      "loss: 1.268675 [19200/60000]\n",
      "loss: 1.134856 [25600/60000]\n",
      "loss: 1.171815 [32000/60000]\n",
      "loss: 1.192126 [38400/60000]\n",
      "loss: 1.126166 [44800/60000]\n",
      "loss: 1.154233 [51200/60000]\n",
      "loss: 1.077512 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.095135 \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}/{epochs}\\n\")\n",
    "  train(train_dl, model, loss_fn, optimizer)\n",
    "  test(test_dl, model, loss_fn)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f61a86f2160>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dl.dataset[1][0].numpy().squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7539, -2.7455,  3.6787, -1.3823,  3.3724, -1.9734,  2.7345, -3.6673,\n",
      "          1.7058, -2.2780]])\n",
      "Predicted: \"Pullover\", Actual: \"Pullover\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[1][0], test_data[1][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    print(pred)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
